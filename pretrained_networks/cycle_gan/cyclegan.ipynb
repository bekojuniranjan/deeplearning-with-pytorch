{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf27778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ad53c",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecba1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('horse.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af7dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be126c0a",
   "metadata": {},
   "source": [
    "## Preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26c764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess  = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611b3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess(img)\n",
    "img_t = torch.unsqueeze(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bce35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 384])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c3e46",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1f97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResNetBlock(nn.Module): # <1>\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim)\n",
    "\n",
    "    def build_conv_block(self, dim):\n",
    "        conv_block = []\n",
    "\n",
    "        conv_block += [nn.ReflectionPad2d(1)]\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "                       nn.InstanceNorm2d(dim),\n",
    "                       nn.ReLU(True)]\n",
    "\n",
    "        conv_block += [nn.ReflectionPad2d(1)]\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "                       nn.InstanceNorm2d(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x) # <2>\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9): # <3> \n",
    "\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=True),\n",
    "                 nn.InstanceNorm2d(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
    "                                stride=2, padding=1, bias=True),\n",
    "                      nn.InstanceNorm2d(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResNetBlock(ngf * mult)]\n",
    "\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=True),\n",
    "                      nn.InstanceNorm2d(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input): # <3>\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05332174",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = ResNetGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29436a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'horse2zebra_0.4.0.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e74e6a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = torch.load(model_path)\n",
    "netG.load_state_dict(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7612199",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = netG(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b945d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = (out.data.squeeze() + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "497a8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = transforms.ToPILImage()(out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e072018",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img.save('zebra.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45593c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
